---
title: "R Notebook"
output: html_notebook
---
```{r}
library(dplyr)
library(ggplot2)
library(lattice)
library(caret)
library(crossval)
```


### Load in train data
```{r}
train_data <- read.csv("https://raw.githubusercontent.com/jitsen-design/Data-621-Group/master/Data/Assignment_1/moneyball-training-data.csv?token=AF5OF3MUSSHCHDGWYDMTRGS6JFZF4")
test_data <- read.csv("https://raw.githubusercontent.com/jitsen-design/Data-621-Group/master/Data/Assignment_1/moneyball-evaluation-data.csv?token=AF5OF3OEVOSPZRLDPQE3YG26JFZI6") 
```


```{r}
train_data
```

### Observe subset of data
```{r}
head(train_data)
```

### Look at dimensions
```{r}
dim(train_data)
```

```{r}
train_data %>%
  summarise_all(list(~sum(is.na(.))))
```

### Check overall summary for each column
```{r}
summary(train_data)
```

### Look at correlation matrix for data with small amount of nulls
```{r}
library(reshape2)
cor_matrix <- cor(train_data[c(2:9,12:16)][complete.cases(train_data[c(2:9,12:16)]),], method = c("pearson", "kendall", "spearman"))
melted_data <- melt(cor_matrix)
ggplot(data=melted_data, aes(x=Var1, y=Var2, fill=value)) + 
  geom_tile() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  ylab("Variable 1") + 
 xlab("Variable 2")
```

### Observe distribution of target variable
```{r, fig.height=3, fig.width=5}
ggplot(train_data, 
       aes(x=TARGET_WINS)) + 
 geom_histogram(aes(y=..density..,),
                bins = 60,
                binwidth = .5) +
 geom_density(alpha=.2, fill='blue') +
 ylab("Density") + 
 xlab("Number of Wins")
```

The distribution looks fairly normal

### Fit regression model to variables with few missing values. get rid of missning values.
```{r}
fit <- lm(formula = TARGET_WINS ~ ., data = train_data[c(2:9,12:16)][complete.cases(train_data[c(2:9,12:16)]),])
summary(fit) # show result
```

### Check to see how many rows were retained
```{r}
 nrow(train_data[c(2:9,12:16)][complete.cases(train_data[c(2:9,12:16)]),])
```

### Analyze residuals
```{r}
library(ggfortify)
autoplot(fit)
```


```{r}
library(DMwR)
knnOutput <- knnImputation(train_data[c(2:9,12:16)])  # perform knn imputation.
anyNA(knnOutput)
```


```{r}
head(knnOutput,5)
nrow(knnOutput)
```

```{r}
fit_knn <- lm(formula = TARGET_WINS ~ ., data = knnOutput)
summary(fit_knn) # show result
```

```{r}
formula = TARGET_WINS ~ .^2
knnOutput_int <- cbind(knnOutput$TARGET_WINS,
                        data.frame(model.matrix(formula, data=knnOutput)))
knnOutput_int <- knnOutput_int %>% 
                        rename(
                          TARGET_WINS = 'knnOutput$TARGET_WINS',
                          INTERCEPT = 'X.Intercept.',
                          ) 
                  
knnOutput_int <- select(knnOutput_int,-c(INTERCEPT))
fit_knn_int <- lm(formula = 'TARGET_WINS ~ .',  data= knnOutput_int)
summary(fit_knn_int) # show result
```

```{r}
formula <- as.formula(paste(' TARGET_WINS ~ .^2 + ', paste('poly(',colnames(knnOutput[,!colnames(knnOutput) %in% 'TARGET_WINS']),',2, raw=TRUE)[, 2]', collapse = ' + ')))
knnOutput_poly_int <- cbind(knnOutput$TARGET_WINS,
                        data.frame(model.matrix(formula, data=knnOutput)))
knnOutput_poly_int <- knnOutput_poly_int %>% 
                        rename(
                          TARGET_WINS = 'knnOutput$TARGET_WINS',
                          INTERCEPT = 'X.Intercept.',
                          ) 
                  
knnOutput_poly_int <- select(knnOutput_poly_int,-c(INTERCEPT))
fit_knn_poly_int <- lm(formula = 'TARGET_WINS ~ .',  data= knnOutput_poly_int)
summary(fit_knn_poly_int) # show result
```

```{r}
autoplot(fit_knn_poly_int)
```

```{r}
train.control <- trainControl(method = "cv", 
                              p = .8,
                              number = 10)
# Train the model 
final_model <- train(TARGET_WINS ~ .,  data= knnOutput_poly_int, method = "lm",
               trControl = train.control)
# Summarize the results
print(final_model)
```


```{r}
head(test_data)
```

```{r}
test_data %>%
  summarise_all(list(~sum(is.na(.))))
```

```{r}
knnOutput_test <- knnImputation(train_data[c(2:9,12:16)]) 
knnOutput_test_poly_int <- cbind(knnOutput_test$TARGET_WINS,
                                 data.frame(model.matrix(formula, data=knnOutput_test)))
knnOutput_test_poly_int <- knnOutput_test_poly_int %>% 
                            rename(
                              TARGET_WINS = 'knnOutput_test$TARGET_WINS',
                              INTERCEPT = 'X.Intercept.',
                              ) 
                  
knnOutput_test_poly_int <- select(knnOutput_test_poly_int,-c(INTERCEPT))
```


```{r}
knnOutput_test_poly_int_pred <- predict(final_model, knnOutput_test_poly_int,
                                        interval = "prediction")
test_result <- postResample(knnOutput_test$TARGET_WINS, knnOutput_test_poly_int_pred)
test_result
```







#Models

##Model: All Variables

All remaining variables after the data prep. After the data has been manipulated (imputed, etc. as stated above), all of the variables will be tested to determine the base model they provided.

```{r}
model1 <- lm(TARGET_WINS ~., knnOutput_int)
summary(model1)
```


**Conclusions based on model:**

F-statistic is 25.59, Adj. R-Squared is 0.4575.  


##Model Backwards elimination and Significance

Variables will be removed one by one to determine best fit model. After each variable is removed, the model will be 'ran' again - until the most optimal output (r2, f-stat) are produced.  The OLSRR library is used to determine the best fit variables for the backwards elimination.  The best variables are then selected and used in the model - rather than having the OLSRR function regenerate the list.

```{r}
#ols_step_backward_p(model1, details=F)
```

```{r}
model_backwards <- lm(
TARGET_WINS ~
TEAM_BATTING_H +
TEAM_BATTING_2B +
TEAM_BATTING_3B +
TEAM_BATTING_HR +
TEAM_BATTING_BB +
TEAM_BATTING_SO +
TEAM_BASERUN_SB +
TEAM_PITCHING_H +
TEAM_PITCHING_HR +
TEAM_PITCHING_BB +
TEAM_PITCHING_SO +
TEAM_FIELDING_E +
TEAM_BATTING_H.TEAM_BATTING_2B +
TEAM_BATTING_H.TEAM_BATTING_3B +
TEAM_BATTING_H.TEAM_BATTING_HR +
TEAM_BATTING_H.TEAM_BATTING_BB +
TEAM_BATTING_H.TEAM_BATTING_SO +
TEAM_BATTING_H.TEAM_BASERUN_SB +
TEAM_BATTING_H.TEAM_PITCHING_H +
TEAM_BATTING_H.TEAM_PITCHING_HR +
TEAM_BATTING_H.TEAM_PITCHING_BB +
TEAM_BATTING_H.TEAM_PITCHING_SO +
TEAM_BATTING_H.TEAM_FIELDING_E +
TEAM_BATTING_2B.TEAM_BATTING_3B +
TEAM_BATTING_2B.TEAM_BATTING_HR +
TEAM_BATTING_2B.TEAM_BATTING_BB +
TEAM_BATTING_2B.TEAM_BATTING_SO +
TEAM_BATTING_2B.TEAM_BASERUN_SB +
TEAM_BATTING_2B.TEAM_PITCHING_H +
TEAM_BATTING_2B.TEAM_PITCHING_HR +
TEAM_BATTING_2B.TEAM_PITCHING_BB +
TEAM_BATTING_2B.TEAM_PITCHING_SO +
TEAM_BATTING_2B.TEAM_FIELDING_E +
TEAM_BATTING_3B.TEAM_BATTING_HR +
TEAM_BATTING_3B.TEAM_BATTING_BB +
TEAM_BATTING_3B.TEAM_BATTING_SO +
TEAM_BATTING_3B.TEAM_BASERUN_SB +
TEAM_BATTING_3B.TEAM_PITCHING_H +
TEAM_BATTING_3B.TEAM_PITCHING_HR +
TEAM_BATTING_3B.TEAM_PITCHING_BB +
TEAM_BATTING_3B.TEAM_PITCHING_SO +
TEAM_BATTING_3B.TEAM_FIELDING_E +
TEAM_BATTING_HR.TEAM_BATTING_BB +
TEAM_BATTING_HR.TEAM_BATTING_SO +
TEAM_BATTING_HR.TEAM_BASERUN_SB +
TEAM_BATTING_HR.TEAM_PITCHING_H +
TEAM_BATTING_HR.TEAM_PITCHING_HR +
TEAM_BATTING_HR.TEAM_PITCHING_BB +
TEAM_BATTING_HR.TEAM_PITCHING_SO +
TEAM_BATTING_HR.TEAM_FIELDING_E +
TEAM_BATTING_BB.TEAM_BATTING_SO +
TEAM_BATTING_BB.TEAM_BASERUN_SB +
TEAM_BATTING_BB.TEAM_PITCHING_H  +
TEAM_BATTING_BB.TEAM_PITCHING_HR +
TEAM_BATTING_BB.TEAM_PITCHING_BB +
TEAM_BATTING_BB.TEAM_PITCHING_SO +
TEAM_BATTING_BB.TEAM_FIELDING_E +
TEAM_BATTING_SO.TEAM_BASERUN_SB +
TEAM_BATTING_SO.TEAM_PITCHING_H +
TEAM_BATTING_SO.TEAM_PITCHING_HR+
TEAM_BATTING_SO.TEAM_PITCHING_BB    +
TEAM_BATTING_SO.TEAM_PITCHING_SO +
TEAM_BATTING_SO.TEAM_FIELDING_E +
TEAM_BASERUN_SB.TEAM_PITCHING_H +
TEAM_BASERUN_SB.TEAM_PITCHING_HR +
TEAM_BASERUN_SB.TEAM_PITCHING_BB +
TEAM_BASERUN_SB.TEAM_PITCHING_SO +
TEAM_BASERUN_SB.TEAM_FIELDING_E +
TEAM_PITCHING_H.TEAM_PITCHING_HR +
TEAM_PITCHING_H.TEAM_PITCHING_BB +
TEAM_PITCHING_H.TEAM_PITCHING_SO +
TEAM_PITCHING_H.TEAM_FIELDING_E +
TEAM_PITCHING_HR.TEAM_PITCHING_BB+ 
TEAM_PITCHING_HR.TEAM_PITCHING_SO +
TEAM_PITCHING_HR.TEAM_FIELDING_E +
TEAM_PITCHING_BB.TEAM_PITCHING_SO +
TEAM_PITCHING_BB.TEAM_FIELDING_E +
TEAM_PITCHING_SO.TEAM_FIELDING_E, data=knnOutput_int)

summary(model_backwards)
```

**Conclusions based on model:**

F-statistic is 25.59, Adj. R-Squared is 0.4575.  

##Model Forward Selection and Significance

Model is based on the stepwise forward regression method.  Variables are entered based on p-values until there are no more variables left to enter. The OLSRR library is used to determine the best fit variables for the backwards elimination.  The best variables are then selected and used in the model - rather than having the OLSRR function regenerate the list.

```{r}
#library(olsrr)
#ols_step_forward_p(model1)
```

```{r}
model_forward <- 
  lm(TARGET_WINS ~
TEAM_BATTING_H +
TEAM_BASERUN_SB +
TEAM_BATTING_HR.TEAM_BATTING_BB +
TEAM_BATTING_2B.TEAM_BATTING_HR +
TEAM_BATTING_BB.TEAM_FIELDING_E +
TEAM_BATTING_HR.TEAM_BASERUN_SB +
TEAM_BATTING_2B.TEAM_BATTING_3B +
TEAM_BATTING_H.TEAM_BATTING_SO +
TEAM_BATTING_2B.TEAM_FIELDING_E +
TEAM_BATTING_3B.TEAM_BATTING_SO +
TEAM_BATTING_3B.TEAM_PITCHING_SO +
TEAM_BATTING_BB.TEAM_PITCHING_BB +
TEAM_BATTING_HR.TEAM_FIELDING_E +
TEAM_BATTING_2B.TEAM_PITCHING_H +
TEAM_BATTING_H.TEAM_BATTING_BB +
TEAM_BATTING_BB +
TEAM_BATTING_BB.TEAM_BATTING_SO +
TEAM_BASERUN_SB.TEAM_FIELDING_E +
TEAM_BATTING_H.TEAM_PITCHING_H +
TEAM_PITCHING_BB.TEAM_FIELDING_E+ 
TEAM_BATTING_SO.TEAM_PITCHING_BB +
TEAM_PITCHING_H +
TEAM_BATTING_2B.TEAM_PITCHING_BB +
TEAM_BATTING_2B +
TEAM_BATTING_3B.TEAM_PITCHING_BB +
TEAM_BATTING_BB.TEAM_BASERUN_SB +
TEAM_BATTING_3B.TEAM_BASERUN_SB +
TEAM_BATTING_BB.TEAM_PITCHING_SO +
TEAM_BATTING_3B.TEAM_BATTING_BB +
TEAM_BATTING_3B.TEAM_BATTING_HR +
TEAM_BATTING_H.TEAM_PITCHING_BB +
TEAM_PITCHING_HR.TEAM_PITCHING_SO+ 
TEAM_BASERUN_SB.TEAM_PITCHING_HR +
TEAM_BATTING_H.TEAM_BATTING_HR +
TEAM_BATTING_3B.TEAM_FIELDING_E +
TEAM_PITCHING_HR.TEAM_PITCHING_BB+ 
TEAM_BASERUN_SB.TEAM_PITCHING_BB +
 TEAM_BATTING_BB.TEAM_PITCHING_HR +
 TEAM_BATTING_H.TEAM_FIELDING_E +
 TEAM_PITCHING_H.TEAM_PITCHING_BB+ 
 TEAM_BATTING_HR.TEAM_PITCHING_BB +
 TEAM_BATTING_2B.TEAM_BATTING_BB +
 TEAM_PITCHING_HR.TEAM_FIELDING_E +
 TEAM_BATTING_3B.TEAM_PITCHING_HR, knnOutput_int)
```

```{r}
summary(model_forward)
```

**Conclusions based on model:**

F-statistic is 44.32, Adj. R-Squared is 0.4559.  


















